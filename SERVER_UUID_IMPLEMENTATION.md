# Server-Generated UUID Implementation

## Overview

**Date:** 2026-01-03
**Status:** ✅ Implemented

This document describes the implementation of server-generated UUIDs for streams, replacing the previous client-generated UUID system.

## Problem Statement

Previously, the client generated stream UUIDs locally using hardcoded StreamId components:
```python
StreamId(source="central", author="satori", stream="observations", target="")
```

This caused **all observations** (Bitcoin, Ethereum, etc.) to be stored in the **same table** because the UUID was identical for all streams.

## Solution

**The server now generates a unique UUID for each stream**, and the client uses that UUID directly.

## Implementation Details

### 1. Server-Side Changes

#### A. Database Schema (`migrations/add_streams_table.sql`)

```sql
CREATE TABLE IF NOT EXISTS streams (
    id SERIAL PRIMARY KEY,
    uuid UUID DEFAULT gen_random_uuid() NOT NULL UNIQUE,  -- Server generates UUID
    name VARCHAR(255) NOT NULL,
    secondary VARCHAR(255),
    target VARCHAR(255),  -- Added for StreamId compatibility
    meta VARCHAR(255),
    description TEXT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL
);
```

**Key changes:**
- `uuid` is `NOT NULL UNIQUE` - every stream has a unique UUID
- `target` field added per user request
- Server auto-generates UUID using PostgreSQL's `gen_random_uuid()`

#### B. Stream Model (`src/models/stream.py`)

```python
class Stream(Base):
    __tablename__ = "streams"

    id = Column(Integer, primary_key=True, autoincrement=True)
    uuid = Column(UUID(as_uuid=True), default=uuid.uuid4, nullable=False, unique=True)
    name = Column(String(255), nullable=False)
    secondary = Column(String(255), nullable=True)
    target = Column(String(255), nullable=True)  # Added
    meta = Column(String(255), nullable=True)
    description = Column(Text, nullable=True)
    ts = Column(DateTime, nullable=False, default=datetime.utcnow)

    observations = relationship("Observation", back_populates="stream")
```

**Key changes:**
- `uuid` is `nullable=False, unique=True`
- `target` field added
- UUID auto-generated by SQLAlchemy using `uuid.uuid4`

#### C. API Response Schema (`src/models/schemas.py`)

```python
class StreamResponse(BaseModel):
    """Stream response model (nested in observation response)."""
    id: int
    uuid: str  # Server-generated UUID
    name: str
    secondary: Optional[str] = None
    target: Optional[str] = None  # Added
    meta: Optional[str] = None
    description: Optional[str] = None

class ObservationResponse(BaseModel):
    """Observation response model."""
    id: int
    observed_at: Optional[str] = None
    value: str
    hash: Optional[str] = None
    stream_id: Optional[int] = None
    stream: Optional[StreamResponse] = None  # Includes uuid
    ts: datetime
```

**Example response:**
```json
{
  "id": 123,
  "value": "45000.50",
  "observed_at": "2026-01-03T12:00:00",
  "hash": "abc123",
  "stream_id": 1,
  "stream": {
    "id": 1,
    "uuid": "7a8b9c0d-1e2f-5a6b-c7d8-e9f0a1b2c3d4",
    "name": "bitcoin",
    "secondary": null,
    "target": null,
    "meta": null,
    "description": "Bitcoin price observations"
  },
  "ts": "2026-01-03T12:00:00"
}
```

### 2. Client-Side Changes

#### A. Client Streams Table (`neuron/migrations/add_client_streams_table.sql`)

```sql
CREATE TABLE IF NOT EXISTS streams (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    server_stream_id INTEGER,  -- Server's stream.id
    uuid TEXT UNIQUE NOT NULL,  -- Server-provided UUID (not generated by client)
    name TEXT,
    secondary TEXT,
    target TEXT,  -- Added
    meta TEXT,
    description TEXT,
    last_synced TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL
);
```

**Key changes:**
- `uuid` is from server (NOT generated by client)
- `server_stream_id` stores the server's stream.id for reference
- `target` field added
- `last_synced` tracks when metadata was last updated

#### B. SQLite Manager (`neuron/engine-lite/storage/sqlite_manager.py`)

Added stream metadata management methods:

```python
def upsertStream(
    self,
    uuid: str,
    server_stream_id: Optional[int] = None,
    name: Optional[str] = None,
    secondary: Optional[str] = None,
    target: Optional[str] = None,  # Added
    meta: Optional[str] = None,
    description: Optional[str] = None
) -> bool:
    """Insert or update stream metadata."""
    # Stores/updates stream metadata using server-provided UUID
```

#### C. Server Client (`neuron/lib-lite/satorilib/server/server.py`)

Updated `getObservation()` to extract and store stream metadata:

```python
def getObservation(self, stream: str = 'bitcoin', storage=None) -> Union[dict, None]:
    """
    Get the latest observation from the Central Server.

    Args:
        stream: The stream/topic to get observations for
        storage: Optional storage manager for storing stream metadata

    Returns:
        dict with observation data and stream_uuid if stream metadata is present
    """
    response = self._makeAuthenticatedCall(...)
    data = response.json()

    # Extract and store stream metadata if present
    if data.get('stream'):
        stream_info = data['stream']
        stream_uuid = stream_info.get('uuid')

        if stream_uuid and storage:
            # Store stream metadata in client's streams table
            storage.db.upsertStream(
                uuid=stream_uuid,
                server_stream_id=stream_info.get('id'),
                name=stream_info.get('name'),
                secondary=stream_info.get('secondary'),
                target=stream_info.get('target'),
                meta=stream_info.get('meta'),
                description=stream_info.get('description')
            )
            # Add stream_uuid to response for easy access
            data['stream_uuid'] = stream_uuid

    return data
```

**Key changes:**
- Accepts `storage` parameter to access database
- Extracts `stream.uuid` from server response
- Calls `upsertStream()` to store metadata locally
- Adds `stream_uuid` to response for downstream use

#### D. Neuron Integration (`neuron/neuron-lite/start.py`)

Updated observation polling to pass storage and use server UUID:

```python
# Get latest observation from central
storage = getattr(self.aiengine, 'storage', None)
observation = self.server.getObservation(storage=storage)

# Get the server-provided stream UUID (if available)
server_stream_uuid = observation.get('stream_uuid')

# Use server's UUID if available
if server_stream_uuid and server_stream_uuid in self.aiengine.streamModels:
    self.aiengine.streamModels[server_stream_uuid].onDataReceived(df)
else:
    # Fall back to existing behavior
    for streamUuid, streamModel in self.aiengine.streamModels.items():
        streamModel.onDataReceived(df)
```

**Key changes:**
- Passes `storage` to `getObservation()`
- Extracts `stream_uuid` from response
- Prioritizes using server-provided UUID for data routing

## Data Flow

### Complete Flow: Server → Client

```
1. Server generates observation:
   - Creates observation record
   - Links to stream (which has server-generated UUID)

2. Server responds to /api/v1/observation/get:
   {
     "value": "45000.50",
     "stream": {
       "id": 1,
       "uuid": "7a8b9c0d-...",  ← Server's UUID
       "name": "bitcoin"
     }
   }

3. Client calls getObservation(storage=storage):
   - Receives response with stream.uuid
   - Calls storage.db.upsertStream() to store metadata
   - Returns observation data with stream_uuid field

4. Client stores stream metadata:
   INSERT INTO streams (uuid, server_stream_id, name, ...)
   VALUES ('7a8b9c0d-...', 1, 'bitcoin', ...)
   ON CONFLICT(uuid) DO UPDATE ...

5. Client uses stream_uuid for data routing:
   - Routes observation to correct streamModel
   - Stores observation in table named by UUID
```

## Benefits

✅ **Centralized Control**: Server controls stream identification
✅ **Proper Data Separation**: Each stream gets its own UUID and table
✅ **Metadata Sync**: Client stores stream metadata locally for reference
✅ **Backward Compatible**: Falls back to existing behavior if no UUID provided
✅ **Scalable**: Easy to add new streams - server assigns UUID automatically

## Migration Path

### For Existing Deployments

1. **Server Migration**:
   ```bash
   psql -U satori -d satori -f migrations/add_streams_table.sql
   ```

2. **Client Migration**:
   ```bash
   sqlite3 /path/to/client.db < neuron/migrations/add_client_streams_table.sql
   ```

3. **Code Deployment**:
   - Deploy server changes first (backward compatible)
   - Deploy client changes after server is updated
   - Old clients will ignore stream metadata
   - New clients will start using server UUIDs

## Testing

### Verify Server UUID Generation

```python
from src.models import Stream
from src.services.database import get_db

db = next(get_db())
stream = Stream(name="bitcoin", description="Bitcoin price")
db.add(stream)
db.commit()
db.refresh(stream)

print(f"Stream ID: {stream.id}")
print(f"Stream UUID: {stream.uuid}")  # Should be auto-generated
print(f"Stream Name: {stream.name}")
```

### Verify Client Storage

```python
from satorilib.server import SatoriServerClient
from satoriengine.veda.storage import EngineStorageManager

server = SatoriServerClient(wallet=wallet)
storage = EngineStorageManager.getInstance()

# Fetch observation (will store stream metadata)
observation = server.getObservation(storage=storage)

# Verify stream metadata was stored
stream = storage.db.getStreamByName("bitcoin")
print(f"Stored UUID: {stream['uuid']}")  # Should match server's UUID
```

## Related Files

### Server
- `/app/Satori/central/migrations/add_streams_table.sql`
- `/app/Satori/central/src/models/stream.py`
- `/app/Satori/central/src/models/schemas.py`
- `/app/Satori/central/src/models/observation.py`

### Client
- `/app/Satori/neuron/migrations/add_client_streams_table.sql`
- `/app/Satori/neuron/engine-lite/storage/sqlite_manager.py`
- `/app/Satori/neuron/lib-lite/satorilib/server/server.py`
- `/app/Satori/neuron/neuron-lite/start.py`

## Future Enhancements

1. **Stream Sync Endpoint**: Add endpoint for clients to bulk-fetch stream metadata
2. **UUID Validation**: Add validation to ensure UUIDs are valid UUID4 format
3. **Stream Discovery**: Allow clients to query available streams by UUID
4. **Migration Tool**: Tool to migrate existing observations to use server UUIDs

## Summary

This implementation fulfills the user requirement: **"the server should provide the uuid and the client should just use that"**

- ✅ Server generates unique UUID for each stream
- ✅ Client receives UUID in observation response
- ✅ Client stores stream metadata locally
- ✅ Client uses server's UUID for data routing and storage
- ✅ Added `target` field as requested
- ✅ Made `uuid` NOT NULL as confirmed
